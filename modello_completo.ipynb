{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINet COD10K Detection\n",
    "Questo notebook implementa SINet per il rilevamento di oggetti mimetizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torch.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametri ottimali: \n",
    "* Adam decay: 1e-4\n",
    "* Resize: 416 x 416\n",
    "* Batch: 40\n",
    "* Epochs: 180 (Provo con 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder,\n",
    "                 image_transform=None, mask_transform=None):\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_folder, self.image_files[idx].replace('.jpg', '.png'))\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(15),\n",
    "    # transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(15),\n",
    "    # transforms.GaussianBlur(kernel_size=(3, 3)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone encoder (ResNet Multi-scale)\n",
    "Estrae feature multi-scala con ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "        self.stage1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu) \n",
    "        self.pool = resnet.maxpool \n",
    "        self.stage2 = resnet.layer1  \n",
    "        self.stage3 = resnet.layer2  \n",
    "        self.stage4 = resnet.layer3 \n",
    "        self.stage5 = resnet.layer4  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.stage1(x)  \n",
    "        x1p = self.pool(x1)   \n",
    "        x2 = self.stage2(x1p)  \n",
    "        x3 = self.stage3(x2)    \n",
    "        x4 = self.stage4(x3) \n",
    "        x5 = self.stage5(x4)  \n",
    "        return x1, x2, x3, x4, x5  # Feature Multi-Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JDPM (Joint Domain perception module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JDPM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=128):\n",
    "        super(JDPM, self).__init__()\n",
    "        self.reduce_channels = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(out_channels, out_channels, kernel_size=5, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reduce_channels(x)\n",
    "        x1 = self.conv1(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x5 = self.conv5(x)\n",
    "        return x1 + x3 + x5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entanglement transformer block (ETB)\n",
    "Modella dipendenze tra frequenze e spazio con self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fft(x_freq):\n",
    "    return (x_freq - x_freq.mean()) / (x_freq.std() + 1e-8)  # Normalizzazione\n",
    "\n",
    "def filter_fft(x_freq, low_cut=5, high_cut=50):\n",
    "    # Creiamo una maschera per tenere solo certe frequenze\n",
    "    mask = (x_freq.abs() > low_cut) & (x_freq.abs() < high_cut)\n",
    "    return x_freq * mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETB(nn.Module):  \n",
    "    def __init__(self, in_channels=128):  \n",
    "        super(ETB, self).__init__()\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "\n",
    "    def fourier_transform(self, x):\n",
    "        \"\"\"\n",
    "        Applica la Trasformata di Fourier 2D e restituisce solo il modulo (magnitude).\n",
    "        Per compatibilità con MPS, la FFT viene calcolata sulla CPU.\n",
    "        \"\"\"\n",
    "        x_cpu = x.to(\"cpu\")  # 🟢 Sposta su CPU prima della FFT\n",
    "        x_freq = fft.fft2(x_cpu, norm=\"ortho\")  # FFT\n",
    "        x_freq = fft.fftshift(x_freq)  # Shift per centrare le basse frequenze\n",
    "\n",
    "        magnitude = torch.abs(x_freq)  # 🟢 Prendiamo solo il modulo per evitare tensori complessi\n",
    "\n",
    "        return magnitude.to(x.device)  # 🟢 Torniamo su GPU dopo il calcolo\n",
    "\n",
    "\n",
    "    def inverse_fourier_transform(self, magnitude):\n",
    "        \"\"\"\n",
    "        Applica l'Inverse Fourier Transform sulla CPU e restituisce il risultato sulla GPU.\n",
    "        \"\"\"\n",
    "        magnitude_cpu = magnitude.to(\"cpu\")  # 🟢 Sposta su CPU\n",
    "        x_ifft = fft.ifftshift(magnitude_cpu)  # Inverso dello shift\n",
    "        x_spatial = fft.ifft2(x_ifft, norm=\"ortho\").real  # 🟢 Prendiamo solo la parte reale\n",
    "\n",
    "        return x_spatial.to(magnitude.device)  # 🟢 Torniamo su GPU dopo il calcolo\n",
    "\n",
    "\n",
    "    def high_pass_filter(self, magnitude, cutoff=0.1):\n",
    "        \"\"\"\n",
    "        Filtro passa-alto per rimuovere le basse frequenze senza usare numeri complessi.\n",
    "        \"\"\"\n",
    "        _, _, H, W = magnitude.shape  # Ottieni dimensioni\n",
    "\n",
    "        # 🟢 Crea una maschera passa-alto\n",
    "        mask = torch.ones((H, W), dtype=magnitude.dtype, device=magnitude.device)\n",
    "        center_x, center_y = H // 2, W // 2  # Centro dell'immagine in frequenza\n",
    "        radius = int(cutoff * min(H, W))  # Raggio della zona da rimuovere\n",
    "\n",
    "        # Rimuovi le basse frequenze (cerchio al centro)\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                if (i - center_x)**2 + (j - center_y)**2 < radius**2:\n",
    "                    mask[i, j] = 0  # Oscuriamo le basse frequenze\n",
    "\n",
    "        # 🟢 Applica il filtro sul modulo delle frequenze\n",
    "        magnitude_filtered = magnitude * mask\n",
    "\n",
    "        return magnitude_filtered\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.norm(x)\n",
    "\n",
    "        # 🟢 Passa allo spazio delle frequenze\n",
    "        magnitude = self.fourier_transform(x_norm)  # ❌ Rimosso il calcolo della fase\n",
    "\n",
    "        # 🔵 **Filtro passa-alto**: rimuove le basse frequenze\n",
    "        magnitude_filtered = self.high_pass_filter(magnitude, cutoff=0.1)\n",
    "\n",
    "        # 🟢 Torna allo spazio spaziale con IFFT\n",
    "        x_spatial = self.inverse_fourier_transform(magnitude_filtered)\n",
    "\n",
    "        # 🔴 Fusione tra feature spaziali e frequenziali\n",
    "        x_combined = x_spatial + self.conv1(x_norm)  \n",
    "\n",
    "        return x_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual-Domain reverse parser (DRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRP(nn.Module):\n",
    "    def __init__(self, in_channels=128):\n",
    "        super(DRP, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def reverse_attention(self, x, mask):\n",
    "        return x * (1 - self.sigmoid(mask))\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.conv(x)\n",
    "        return self.reverse_attention(x, mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementazione della Focal Loss per segmentazione binaria.\n",
    "    Penalizza gli esempi facili e enfatizza quelli difficili.\n",
    "\n",
    "    Args:\n",
    "        alpha (float): Peso per la classe positiva (oggetto).\n",
    "        gamma (float): Fattore di riduzione per gli esempi facili.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.75, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha  # Peso per la classe positiva (oggetto)\n",
    "        self.gamma = gamma  # Penalizzazione sugli esempi facili\n",
    "        self.reduction = reduction  # mean, sum, none\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        \"\"\"\n",
    "        Calcola la Focal Loss.\n",
    "\n",
    "        Args:\n",
    "            preds (torch.Tensor): Predizioni del modello (logits o probabilità).\n",
    "            targets (torch.Tensor): Maschere ground truth binarie.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Loss focalizzata.\n",
    "        \"\"\"\n",
    "\n",
    "        preds = preds.view(-1)  # Flatten\n",
    "        targets = targets.view(-1)  # Flatten\n",
    "\n",
    "        # 🟢 Calcola la Binary Cross Entropy Loss (senza riduzione)\n",
    "        bce_loss = F.binary_cross_entropy(preds, targets, reduction='none')\n",
    "\n",
    "        # 🟢 Calcola il peso degli esempi difficili (1 - pt)^gamma\n",
    "        pt = torch.exp(-bce_loss)  # Probabilità corretta\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "\n",
    "        # 🟢 Restituisci la loss nel formato corretto\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SINet Class\n",
    "Combina tutti i moduli e produce output finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINet(nn.Module):\n",
    "    def __init__(self, backbone_pretrained=True):\n",
    "        super(SINet, self).__init__()\n",
    "        self.backbone = ResNetBackbone(pretrained=backbone_pretrained)\n",
    "\n",
    "        # Moduli di FSEL\n",
    "        self.jdpm = JDPM(in_channels=2048, out_channels=128)\n",
    "        self.etb = ETB(in_channels=128)\n",
    "        self.drp = DRP(in_channels=128)\n",
    "\n",
    "        self.output_conv = nn.Conv2d(128, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5 = self.backbone(x)\n",
    "\n",
    "        # Fusione spaziale e frequenziale\n",
    "        x_fused = self.jdpm(x5)\n",
    "\n",
    "        # Apprendimento entangled di feature frequenziali e spaziali\n",
    "        x_etb = self.etb(x_fused)\n",
    "\n",
    "        # Reverse attention per migliorare segmentazione\n",
    "        x_drp = self.drp(x_etb, x_fused)\n",
    "\n",
    "        # Mappa finale segmentata\n",
    "        output = torch.sigmoid(self.output_conv(x_drp))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth=1.0):\n",
    "    if pred.shape[2:] != target.shape[2:]:\n",
    "        pred = F.interpolate(pred, size=target.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    intersection = (pred * target).sum()\n",
    "    return 1 - ((2.0 * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n",
    "\n",
    "\n",
    "def compute_metrics(pred, target, threshold=0.5):\n",
    "    pred_bin = (pred >= threshold).float()\n",
    "    \n",
    "    TP = (pred_bin * target).sum().item()\n",
    "    FP = (pred_bin * (1 - target)).sum().item()\n",
    "    FN = ((1 - pred_bin) * target).sum().item()\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-7)\n",
    "    recall = TP / (TP + FN + 1e-7)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "    iou = TP / (TP + FP + FN + 1e-7)\n",
    "\n",
    "    return {\"iou\": iou, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Funzione per addestrare il modello SINet con FFT.\n",
    "\n",
    "    Args:\n",
    "        model: Modello PyTorch (SINet)\n",
    "        train_loader: DataLoader per il training\n",
    "        val_loader: DataLoader per la validazione\n",
    "        optimizer: Ottimizzatore (Adam, SGD, ecc.)\n",
    "        device: 'cuda', 'mps' o 'cpu'\n",
    "        num_epochs: Numero di epoche\n",
    "        save_path: Percorso per salvare il miglior modello\n",
    "\n",
    "    Returns:\n",
    "        model: Modello addestrato\n",
    "    \"\"\"\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(images)\n",
    "\n",
    "            predictions_resized = F.interpolate(predictions, size=masks.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = dice_loss(predictions_resized, masks) + F.binary_cross_entropy(predictions_resized, masks)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_iou, all_f1 = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                predictions = model(images)\n",
    "\n",
    "\n",
    "                predictions_resized = F.interpolate(predictions, size=masks.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss = 0.5 * FocalLoss(alpha=0.75, gamma=2.0)(predictions_resized, masks) + 0.5 * dice_loss(predictions_resized, masks)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predictions_resized = F.interpolate(predictions, size=masks.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "                batch_metrics = compute_metrics(predictions_resized, masks)\n",
    "\n",
    "                all_iou.append(batch_metrics['iou'])\n",
    "                all_f1.append(batch_metrics['f1'])\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        avg_iou = sum(all_iou) / len(all_iou)\n",
    "        avg_f1 = sum(all_f1) / len(all_f1)\n",
    "\n",
    "        epoch_duration = timedelta(seconds=time.time() - start_time)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, IoU: {avg_iou:.4f}, F1: {avg_f1:.4f}, Time: {epoch_duration}\")\n",
    "\n",
    "\n",
    "    print(\"Training completato!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 50\n",
    "lr = 1e-4\n",
    "\n",
    "train_dataset = CODDataset(\n",
    "    image_folder=\"COD10K-v3/Train/Image\",\n",
    "    mask_folder=\"COD10K-v3/Train/GT_Object\",\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")   \n",
    "val_dataset = CODDataset(\n",
    "    image_folder=\"COD10K-v3/Train/Image\",\n",
    "    mask_folder=\"COD10K-v3/Train/GT_Object\",\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "test_dataset = CODDataset(\"COD10K-v3/Test/Image\",\n",
    "                        \"COD10K-v3/Test/GT_Object\",\n",
    "                        image_transform=image_transform, \n",
    "                        mask_transform=mask_transform\n",
    "                        )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SINet(backbone_pretrained=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "trained_model = train_model(model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"sinet_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_metrics(pred, target, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcola accuracy, precision, recall, F1-score e IoU per un batch di immagini.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predizioni del modello (logits o probabilità)\n",
    "        target (torch.Tensor): Maschere ground truth binarie\n",
    "        threshold (float): Soglia per binarizzare le predizioni\n",
    "\n",
    "    Returns:\n",
    "        dict: Dizionario con le metriche medie sul batch\n",
    "    \"\"\"\n",
    "\n",
    "    # 🟢 Ridimensiona pred per matchare target\n",
    "    if pred.shape[2:] != target.shape[2:]:\n",
    "        pred = F.interpolate(pred, size=target.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    pred_bin = (pred >= threshold).float()\n",
    "\n",
    "    eps = 1e-7\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    acc_list, prec_list, rec_list, f1_list, iou_list = [], [], [], [], []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        p = pred_bin[i].view(-1)  # Flatten per batch\n",
    "        t = target[i].view(-1)  \n",
    "\n",
    "        TP = (p * t).sum().item()\n",
    "        FP = (p * (1 - t)).sum().item()\n",
    "        FN = ((1 - p) * t).sum().item()\n",
    "        TN = ((1 - p) * (1 - t)).sum().item()\n",
    "\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "        prec = TP / (TP + FP + eps)\n",
    "        rec = TP / (TP + FN + eps)\n",
    "        f1 = 2 * prec * rec / (prec + rec + eps)\n",
    "        iou = TP / (TP + FP + FN + eps)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)\n",
    "        f1_list.append(f1)\n",
    "        iou_list.append(iou)\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': np.mean(acc_list),\n",
    "        'precision': np.mean(prec_list),\n",
    "        'recall': np.mean(rec_list),\n",
    "        'f1': np.mean(f1_list),\n",
    "        'iou': np.mean(iou_list)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Testa il modello su un dataset di test e calcola le metriche medie.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Modello addestrato\n",
    "        test_loader (DataLoader): DataLoader con il dataset di test\n",
    "        device (str): 'cuda', 'mps' o 'cpu'\n",
    "        threshold (float): Soglia per binarizzare le predizioni\n",
    "\n",
    "    Returns:\n",
    "        dict: Dizionario con le metriche medie su tutto il dataset di test\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_acc, all_prec, all_rec, all_f1, all_iou = [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            out_final = model(images)\n",
    "\n",
    "            # 🟢 Calcola metriche per batch\n",
    "            batch_metrics = compute_batch_metrics(out_final, masks, threshold)\n",
    "            all_acc.append(batch_metrics['accuracy'])\n",
    "            all_prec.append(batch_metrics['precision'])\n",
    "            all_rec.append(batch_metrics['recall'])\n",
    "            all_f1.append(batch_metrics['f1'])\n",
    "            all_iou.append(batch_metrics['iou'])\n",
    "\n",
    "    # 🟢 Media finale delle metriche su tutto il test set\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean(all_acc),\n",
    "        'precision': np.mean(all_prec),\n",
    "        'recall': np.mean(all_rec),\n",
    "        'f1': np.mean(all_f1),\n",
    "        'iou': np.mean(all_iou)\n",
    "    }\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🟢 Testa il modello\n",
    "test_metrics = test_model(model, test_loader, device, threshold=0.5)\n",
    "\n",
    "# 📊 Stampa i risultati finali\n",
    "print(\"\\n🎯 **RISULTATI TEST FINALI:**\")\n",
    "print(f\"  Accuracy  = {test_metrics['accuracy']:.3f}\")\n",
    "print(f\"  Precision = {test_metrics['precision']:.3f}\")\n",
    "print(f\"  Recall    = {test_metrics['recall']:.3f}\")\n",
    "print(f\"  F1-score  = {test_metrics['f1']:.3f}\")\n",
    "print(f\"  IoU       = {test_metrics['iou']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_predictions(model, test_loader, device, num_samples=5, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Mostra immagini casuali dal dataset di test con la loro maschera e la predizione del modello.\n",
    "\n",
    "    Args:\n",
    "        model: Modello PyTorch addestrato (SINet)\n",
    "        test_loader: DataLoader con il dataset di test\n",
    "        device: 'cuda', 'mps' o 'cpu'\n",
    "        num_samples: Numero di immagini da visualizzare\n",
    "        threshold: Soglia per binarizzare le predizioni\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Estrai batch casuale dal test_loader\n",
    "    images, masks = next(iter(test_loader))\n",
    "\n",
    "    # 🟢 Evita di selezionare più immagini di quante ne siano disponibili\n",
    "    num_samples = min(num_samples, images.shape[0])  # Non supera il batch size\n",
    "\n",
    "    # Seleziona un sottoinsieme casuale di immagini dal batch\n",
    "    indices = random.sample(range(len(images)), num_samples)\n",
    "    images, masks = images[indices], masks[indices]\n",
    "\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "\n",
    "    # 🟢 Ridimensiona predictions per matchare masks\n",
    "    predictions_resized = F.interpolate(predictions, size=masks.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    # 🟢 Applica threshold alle predizioni per ottenere maschere binarie\n",
    "    predictions_binary = (predictions_resized >= threshold).float()\n",
    "\n",
    "    # 📊 Mostra le immagini originali, maschere e predizioni\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(10, num_samples * 3))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()  # Converti da tensor a numpy\n",
    "        mask = masks[i].squeeze().cpu().numpy()\n",
    "        pred = predictions_binary[i].squeeze().cpu().numpy()\n",
    "\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title(\"Immagine originale\")\n",
    "        axes[i, 1].imshow(mask, cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Maschera reale\")\n",
    "        axes[i, 2].imshow(pred, cmap=\"gray\")\n",
    "        axes[i, 2].set_title(\"Predizione modello\")\n",
    "\n",
    "        for ax in axes[i]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_predictions(model, test_loader, device, num_samples=10)   # Mostrerà 10 immagini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
