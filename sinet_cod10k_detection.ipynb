{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846d28c2",
   "metadata": {},
   "source": [
    "# SINet COD10K Detection\n",
    "Questo notebook implementa SINet per il rilevamento di oggetti mimetizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba989901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torch.fft as fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f24b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa931d",
   "metadata": {},
   "source": [
    "### Parametri ottimali: \n",
    "* Adam decay: 1e-4\n",
    "* Resize: 416 x 416\n",
    "* Batch: 40\n",
    "* Epochs: 180 (Provo con 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ea9e7",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a294171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder,\n",
    "                 image_transform=None, mask_transform=None):\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_folder, self.image_files[idx].replace('.jpg', '.png'))\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41f5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(15),\n",
    "    # transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(15),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0144d4f",
   "metadata": {},
   "source": [
    "### Backbone feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df8c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "        self.stage1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu) \n",
    "        self.pool = resnet.maxpool \n",
    "        self.stage2 = resnet.layer1  \n",
    "        self.stage3 = resnet.layer2  \n",
    "        self.stage4 = resnet.layer3 \n",
    "        self.stage5 = resnet.layer4  \n",
    "\n",
    "\n",
    "    def fourier_transform(self, x):\n",
    "        x_cpu = x.detach().cpu().numpy()  # Converti in NumPy\n",
    "        x_freq = np.fft.fft2(x_cpu, norm=\"ortho\")  # FFT\n",
    "        x_freq = np.fft.fftshift(x_freq)  # Shift per centrare\n",
    "        x_freq = np.abs(x_freq)  # Modulo\n",
    "        return torch.tensor(x_freq, dtype=torch.float32).to(device)  # Torna a Torch su MPS\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fourier_transform(x)  # Applicazione della FFT all'input\n",
    "        x1 = self.stage1(x)\n",
    "        x1p = self.pool(x1)     \n",
    "        x2 = self.stage2(x1p)  \n",
    "        x3 = self.stage3(x2)    \n",
    "        x4 = self.stage4(x3) \n",
    "        x5 = self.stage5(x4)  \n",
    "        return x1, x2, x3, x4, x5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e050d",
   "metadata": {},
   "source": [
    "### Search Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08adbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchModule(nn.Module):\n",
    "    def __init__(self, in_channels_list=[256, 512, 1024]):\n",
    "        super(SearchModule, self).__init__()\n",
    "        self.conv_list = nn.ModuleList([\n",
    "            nn.Conv2d(in_ch, 256, kernel_size=3, padding=1) \n",
    "            for in_ch in in_channels_list\n",
    "        ])\n",
    "        self.out_conv = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "\n",
    "    def fourier_transform(self, x):\n",
    "        x_cpu = x.detach().cpu().numpy()  # Converti in NumPy\n",
    "        x_freq = np.fft.fft2(x_cpu, norm=\"ortho\")  # FFT\n",
    "        x_freq = np.fft.fftshift(x_freq)  # Shift per centrare\n",
    "        x_freq = np.abs(x_freq)  # Modulo\n",
    "        return torch.tensor(x_freq, dtype=torch.float32).to(device)  # Torna a Torch su MPS\n",
    "\n",
    "\n",
    "    def forward(self, x2, x3, x4):\n",
    "        x2_ = self.fourier_transform(self.conv_list[0](x2))            \n",
    "        x3_ = self.fourier_transform(F.interpolate(self.conv_list[1](x3), size=x2_.shape[2:], mode='bilinear', align_corners=False))\n",
    "        x4_ = self.fourier_transform(F.interpolate(self.conv_list[2](x4), size=x2_.shape[2:], mode='bilinear', align_corners=False))\n",
    "        \n",
    "        fused = x2_ + x3_ + x4_\n",
    "        coarse_map = self.out_conv(fused)\n",
    "        coarse_map = torch.sigmoid(coarse_map)\n",
    "        return coarse_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67098bbc",
   "metadata": {},
   "source": [
    "### Identification Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2387e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentificationModule(nn.Module):\n",
    "    def __init__(self, in_channels=2048):\n",
    "        super(IdentificationModule, self).__init__()\n",
    "        self.conv_deep = nn.Conv2d(in_channels, 256, kernel_size=3, padding=1)\n",
    "        self.refine_conv = nn.Conv2d(256+1, 256, kernel_size=3, padding=1) \n",
    "        self.out_conv = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x5, coarse_map):\n",
    "\n",
    "        x5_ = self.conv_deep(x5)   \n",
    "        x5_up = F.interpolate(x5_, scale_factor=8, mode='bilinear', align_corners=False)\n",
    "\n",
    "        refine_input = torch.cat([x5_up, coarse_map], dim=1) \n",
    "\n",
    "        refine_feat = self.refine_conv(refine_input)         \n",
    "\n",
    "        out_map = self.out_conv(refine_feat)                  \n",
    "        out_map = torch.sigmoid(out_map)\n",
    "\n",
    "        return out_map  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3992f9",
   "metadata": {},
   "source": [
    "### SINet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6483a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINet(nn.Module):\n",
    "    def __init__(self, backbone_pretrained=True):\n",
    "        super(SINet, self).__init__()\n",
    "        self.backbone = ResNetBackbone(pretrained=backbone_pretrained)\n",
    "   \n",
    "        self.search = SearchModule(in_channels_list=[256, 512, 1024])\n",
    "     \n",
    "        self.identify = IdentificationModule(in_channels=2048)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1, x2, x3, x4, x5 = self.backbone(x)\n",
    "\n",
    "        coarse_map = self.search(x2, x3, x4)   \n",
    "\n",
    "        refine_map = self.identify(x5, coarse_map)  \n",
    "\n",
    "        out_final = F.interpolate(refine_map, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "\n",
    "        return out_final, coarse_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd33f5ca",
   "metadata": {},
   "source": [
    "### Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "343bec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_metrics(pred, target, threshold=0.5):\n",
    "\n",
    "    pred_bin = (pred >= threshold).float()\n",
    "\n",
    "    eps = 1e-7\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    acc_list, prec_list, rec_list, f1_list, iou_list = [], [], [], [], []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        p = pred_bin[i].view(-1)   \n",
    "        t = target[i].view(-1)    \n",
    "\n",
    "        TP = (p * t).sum().item()\n",
    "        FP = (p * (1 - t)).sum().item()\n",
    "        FN = ((1 - p) * t).sum().item()\n",
    "        TN = ((1 - p) * (1 - t)).sum().item()\n",
    "\n",
    "\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "       \n",
    "        prec = TP / (TP + FP + eps)\n",
    "\n",
    "        rec = TP / (TP + FN + eps)\n",
    "\n",
    "        f1 = 2 * prec * rec / (prec + rec + eps)\n",
    "  \n",
    "        union = TP + FP + FN\n",
    "        iou = TP / (union + eps)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)\n",
    "        f1_list.append(f1)\n",
    "        iou_list.append(iou)\n",
    "\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': np.mean(acc_list),\n",
    "        'precision': np.mean(prec_list),\n",
    "        'recall': np.mean(rec_list),\n",
    "        'f1': np.mean(f1_list),\n",
    "        'iou': np.mean(iou_list)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f3cde",
   "metadata": {},
   "source": [
    "### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e93c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth=1.0):\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    intersection = (pred * target).sum()\n",
    "    return 1 - ((2.0 * intersection + smooth) / (pred.sum() + target.sum() + smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678f397",
   "metadata": {},
   "source": [
    "### Train Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f611c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for images, masks in dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_final, out_coarse = model(images)\n",
    "\n",
    "        loss_final = dice_loss(out_final, masks) + F.binary_cross_entropy(out_final, masks)\n",
    "\n",
    "        loss_coarse = dice_loss(out_coarse, F.interpolate(masks, size=out_coarse.shape[2:], mode='nearest')) \\\n",
    "                      + F.binary_cross_entropy(out_coarse, F.interpolate(masks, size=out_coarse.shape[2:], mode='nearest'))\n",
    "\n",
    "        loss = loss_final + 0.5 * loss_coarse\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate_one_epoch(model, dataloader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_acc, all_prec, all_rec, all_f1, all_iou = [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            out_final, out_coarse = model(images)\n",
    "\n",
    "            loss_final = dice_loss(out_final, masks) + F.binary_cross_entropy(out_final, masks)\n",
    "            loss_coarse = dice_loss(out_coarse, F.interpolate(masks, size=out_coarse.shape[2:], mode='nearest')) \\\n",
    "                          + F.binary_cross_entropy(out_coarse, F.interpolate(masks, size=out_coarse.shape[2:], mode='nearest'))\n",
    "            loss = loss_final + 0.5 * loss_coarse\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            batch_metrics = compute_batch_metrics(out_final, masks, threshold=0.5)\n",
    "            all_acc.append(batch_metrics['accuracy'])\n",
    "            all_prec.append(batch_metrics['precision'])\n",
    "            all_rec.append(batch_metrics['recall'])\n",
    "            all_f1.append(batch_metrics['f1'])\n",
    "            all_iou.append(batch_metrics['iou'])\n",
    "\n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean(all_acc),\n",
    "        'precision': np.mean(all_prec),\n",
    "        'recall': np.mean(all_rec),\n",
    "        'f1': np.mean(all_f1),\n",
    "        'iou': np.mean(all_iou)\n",
    "    }\n",
    "    return avg_loss, avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ea930",
   "metadata": {},
   "source": [
    "### Test Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8944f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, device, threshold=0.5):\n",
    "\n",
    "    model.eval()\n",
    "    all_acc, all_prec, all_rec, all_f1, all_iou = [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            \n",
    "\n",
    "            out_final, out_coarse = model(images)\n",
    "\n",
    "            batch_metrics = compute_batch_metrics(out_final, masks, threshold=threshold)\n",
    "            all_acc.append(batch_metrics['accuracy'])\n",
    "            all_prec.append(batch_metrics['precision'])\n",
    "            all_rec.append(batch_metrics['recall'])\n",
    "            all_f1.append(batch_metrics['f1'])\n",
    "            all_iou.append(batch_metrics['iou'])\n",
    "\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean(all_acc),\n",
    "        'precision': np.mean(all_prec),\n",
    "        'recall': np.mean(all_rec),\n",
    "        'f1': np.mean(all_f1),\n",
    "        'iou': np.mean(all_iou)\n",
    "    }\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857df341",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03a2e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "lr = 1e-4\n",
    "\n",
    "train_dataset = CODDataset(\n",
    "    image_folder=\"COD10K-v3/Train/Image\",\n",
    "    mask_folder=\"COD10K-v3/Train/GT_Object\",\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")   \n",
    "val_dataset = CODDataset(\n",
    "    image_folder=\"COD10K-v3/Train/Image\",\n",
    "    mask_folder=\"COD10K-v3/Train/GT_Object\",\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "test_dataset = CODDataset(\"COD10K-v3/Test/Image\",\n",
    "                        \"COD10K-v3/Test/GT_Object\",\n",
    "                        image_transform=image_transform, \n",
    "                        mask_transform=mask_transform\n",
    "                        )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79677cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SINet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss, _ = validate_one_epoch(model, val_loader, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11df13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"sinet_camouflage_fft.pth\")\n",
    "print(\"Training completato e modello salvato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = test_model(model, test_loader, device, threshold=0.5)\n",
    "print(\"RISULTATI TEST FINALI:\")\n",
    "print(f\"  Accuracy = {test_metrics['accuracy']:.3f}\")\n",
    "print(f\"  Precision = {test_metrics['precision']:.3f}\")\n",
    "print(f\"  Recall = {test_metrics['recall']:.3f}\")\n",
    "print(f\"  F1-score = {test_metrics['f1']:.3f}\")\n",
    "print(f\"  IoU = {test_metrics['iou']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dca76d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def visualize_random_samples(model, dataset, device, num_images=8):\n",
    "    \"\"\"\n",
    "    Pesca `num_images` campioni random dal `dataset`,\n",
    "    fa la predizione e visualizza (input, mask, prediction).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Estraggo `num_images` indici casuali senza rimpiazzo\n",
    "    random_indices = np.random.choice(len(dataset), size=num_images, replace=False)\n",
    "\n",
    "    # Liste per accumulare tensori\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "\n",
    "    for idx in random_indices:\n",
    "        image, mask = dataset[idx]  # <--- CODDataset.__getitem__(idx)\n",
    "        images_list.append(image)\n",
    "        masks_list.append(mask)\n",
    "\n",
    "    # Stack su dimensione batch\n",
    "    images_tensor = torch.stack(images_list, dim=0).to(device)\n",
    "    masks_tensor = torch.stack(masks_list, dim=0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_final, _ = model(images_tensor)  # Estrai solo out_final\n",
    "        preds = F.interpolate(out_final, size=masks_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        preds_bin = (preds > 0.5).float()\n",
    "\n",
    "    images_cpu = images_tensor.cpu()\n",
    "    masks_cpu = masks_tensor.cpu()\n",
    "    preds_cpu = preds_bin.cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_images, ncols=3, figsize=(9, 3*num_images))\n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(num_images):\n",
    "        img_np = images_cpu[i].permute(1, 2, 0).numpy()\n",
    "        mask_np = masks_cpu[i].squeeze(0).numpy()\n",
    "        pred_np = preds_cpu[i].squeeze(0).numpy()\n",
    "\n",
    "        axes[i][0].imshow(img_np)\n",
    "        axes[i][0].set_title(\"Input Image\")\n",
    "        axes[i][0].axis(\"off\")\n",
    "\n",
    "        axes[i][1].imshow(mask_np, cmap='gray')\n",
    "        axes[i][1].set_title(\"Ground Truth\")\n",
    "        axes[i][1].axis(\"off\")\n",
    "\n",
    "        axes[i][2].imshow(pred_np, cmap='gray')\n",
    "        axes[i][2].set_title(\"Prediction\")\n",
    "        axes[i][2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_samples(model, test_dataset, device, num_images=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
